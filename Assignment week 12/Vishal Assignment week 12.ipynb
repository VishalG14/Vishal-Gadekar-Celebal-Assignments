{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00806515-f381-4192-a49f-08f3ca978b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce80724a-0576-4e8a-8c1e-8eaef37bcbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-ai-textanalytics==5.2.0\n",
      "  Downloading azure_ai_textanalytics-5.2.0-py3-none-any.whl.metadata (69 kB)\n",
      "     ---------------------------------------- 0.0/69.8 kB ? eta -:--:--\n",
      "     ----------------- ---------------------- 30.7/69.8 kB 1.3 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 30.7/69.8 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 69.8/69.8 kB 541.7 kB/s eta 0:00:00\n",
      "Collecting azure-core<2.0.0,>=1.24.0 (from azure-ai-textanalytics==5.2.0)\n",
      "  Downloading azure_core-1.30.2-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting msrest>=0.7.0 (from azure-ai-textanalytics==5.2.0)\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting azure-common~=1.1 (from azure-ai-textanalytics==5.2.0)\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\spide\\anaconda3\\lib\\site-packages (from azure-ai-textanalytics==5.2.0) (4.11.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\spide\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.2.0) (2.32.2)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\spide\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.2.0) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\spide\\anaconda3\\lib\\site-packages (from msrest>=0.7.0->azure-ai-textanalytics==5.2.0) (2024.7.4)\n",
      "Collecting isodate>=0.6.0 (from msrest>=0.7.0->azure-ai-textanalytics==5.2.0)\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.7.0->azure-ai-textanalytics==5.2.0)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\spide\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.2.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\spide\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.2.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\spide\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.2.0) (2.2.2)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.7.0->azure-ai-textanalytics==5.2.0)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading azure_ai_textanalytics-5.2.0-py3-none-any.whl (239 kB)\n",
      "   ---------------------------------------- 0.0/239.3 kB ? eta -:--:--\n",
      "   ---------------------------------------  235.5/239.3 kB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 239.3/239.3 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Downloading azure_core-1.30.2-py3-none-any.whl (194 kB)\n",
      "   ---------------------------------------- 0.0/194.3 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 174.1/194.3 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 194.3/194.3 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.4/85.4 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.7/41.7 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "   ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 151.7/151.7 kB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: azure-common, oauthlib, isodate, requests-oauthlib, azure-core, msrest, azure-ai-textanalytics\n",
      "Successfully installed azure-ai-textanalytics-5.2.0 azure-common-1.1.28 azure-core-1.30.2 isodate-0.6.1 msrest-0.7.1 oauthlib-3.2.2 requests-oauthlib-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install azure-ai-textanalytics==5.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3b67e5a-41f2-4064-a43a-81d588d5a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25268c6d-e2fa-47a9-a69d-d986cc81fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_endpoint = \"https://vishal-celebal-week12.cognitiveservices.azure.com/\"\n",
    "language_key = \"761f6845bd574430938b108d30d500f0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c25db10-7fd7-45ab-b7cb-5aa0829ca651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(language_key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=language_endpoint, \n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c004ef0b-5d59-4305-9801-32ab4bce0366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Sentiment: mixed\n",
      "Overall scores: positive=0.30; neutral=0.17; negative=0.52 \n",
      "\n",
      "Sentence: The food and service were unacceptable. \n",
      "Sentence sentiment: negative\n",
      "Sentence score:\n",
      "Positive=0.00\n",
      "Neutral=0.00\n",
      "Negative=1.00\n",
      "\n",
      "......'negative' target 'food'\n",
      "......Target score:\n",
      "......Positive=0.01\n",
      "......Negative=0.99\n",
      "\n",
      "......'negative' assessment 'unacceptable'\n",
      "......Assessment score:\n",
      "......Positive=0.01\n",
      "......Negative=0.99\n",
      "\n",
      "......'negative' target 'service'\n",
      "......Target score:\n",
      "......Positive=0.01\n",
      "......Negative=0.99\n",
      "\n",
      "......'negative' assessment 'unacceptable'\n",
      "......Assessment score:\n",
      "......Positive=0.01\n",
      "......Negative=0.99\n",
      "\n",
      "\n",
      "\n",
      "Sentence: The concierge was nice, however.\n",
      "Sentence sentiment: positive\n",
      "Sentence score:\n",
      "Positive=0.61\n",
      "Neutral=0.35\n",
      "Negative=0.05\n",
      "\n",
      "......'positive' target 'concierge'\n",
      "......Target score:\n",
      "......Positive=1.00\n",
      "......Negative=0.00\n",
      "\n",
      "......'positive' assessment 'nice'\n",
      "......Assessment score:\n",
      "......Positive=1.00\n",
      "......Negative=0.00\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sentiment_analysis_with_opinion_mining_example(client):\n",
    "\n",
    "    documents = [\n",
    "        \"The food and service were unacceptable. The concierge was nice, however.\"\n",
    "    ]\n",
    "\n",
    "    result = client.analyze_sentiment(documents, show_opinion_mining=True)\n",
    "    doc_result = [doc for doc in result if not doc.is_error]\n",
    "\n",
    "    positive_reviews = [doc for doc in doc_result if doc.sentiment == \"positive\"]\n",
    "    negative_reviews = [doc for doc in doc_result if doc.sentiment == \"negative\"]\n",
    "\n",
    "    positive_mined_opinions = []\n",
    "    mixed_mined_opinions = []\n",
    "    negative_mined_opinions = []\n",
    "\n",
    "    for document in doc_result:\n",
    "        print(\"Document Sentiment: {}\".format(document.sentiment))\n",
    "        print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "            document.confidence_scores.positive,\n",
    "            document.confidence_scores.neutral,\n",
    "            document.confidence_scores.negative,\n",
    "        ))\n",
    "        for sentence in document.sentences:\n",
    "            print(\"Sentence: {}\".format(sentence.text))\n",
    "            print(\"Sentence sentiment: {}\".format(sentence.sentiment))\n",
    "            print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
    "                sentence.confidence_scores.positive,\n",
    "                sentence.confidence_scores.neutral,\n",
    "                sentence.confidence_scores.negative,\n",
    "            ))\n",
    "            for mined_opinion in sentence.mined_opinions:\n",
    "                target = mined_opinion.target\n",
    "                print(\"......'{}' target '{}'\".format(target.sentiment, target.text))\n",
    "                print(\"......Target score:\\n......Positive={0:.2f}\\n......Negative={1:.2f}\\n\".format(\n",
    "                    target.confidence_scores.positive,\n",
    "                    target.confidence_scores.negative,\n",
    "                ))\n",
    "                for assessment in mined_opinion.assessments:\n",
    "                    print(\"......'{}' assessment '{}'\".format(assessment.sentiment, assessment.text))\n",
    "                    print(\"......Assessment score:\\n......Positive={0:.2f}\\n......Negative={1:.2f}\\n\".format(\n",
    "                        assessment.confidence_scores.positive,\n",
    "                        assessment.confidence_scores.negative,\n",
    "                    ))\n",
    "            print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "          \n",
    "sentiment_analysis_with_opinion_mining_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49979e1a-46aa-472f-a377-85106836e684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
